{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **ASTREA - TAKE-HOME EXERCISE FOR DATA SCIENCE**\n",
    "\n",
    "### **DISCRETE CHOICE MODEL INTERPRETATION & BUSINESS RECOMMENDATIONS**\n",
    "\n",
    "#### **BY: DAVID GUZZI**  \n",
    "\n",
    "**MARCH 2025**  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **TASKS**\n",
    "\n",
    "#### **1. MODEL INTERPRETATION**\n",
    "- Examine the model coefficients and explain what they indicate about consumer preferences.  \n",
    "- Identify any potential concerns or inconsistencies in the output (e.g., extreme coefficients, unrealistic substitution patterns).  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variable</th>\n",
       "      <th>Coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>const</td>\n",
       "      <td>-3.289498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>price</td>\n",
       "      <td>-0.584335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>brand_strength</td>\n",
       "      <td>0.310713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>quality_score</td>\n",
       "      <td>1.200612</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Variable  Coefficient\n",
       "0           const    -3.289498\n",
       "1           price    -0.584335\n",
       "2  brand_strength     0.310713\n",
       "3   quality_score     1.200612"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import model coefficients.\n",
    "coef_path = r\"C:\\Users\\HP\\OneDrive\\Escritorio\\David Guzzi\\Github\\Python-Projects\\astrea\\logit_coefficients.csv\"\n",
    "coef = pd.read_csv(coef_path, delimiter=\",\")\n",
    "coef"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To achieve a proper understanding of the available coefficients, a brief inspection of the dataset is performed.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>respondent_id</th>\n",
       "      <th>trip_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>price</th>\n",
       "      <th>brand_strength</th>\n",
       "      <th>quality_score</th>\n",
       "      <th>group</th>\n",
       "      <th>choice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>2.911052</td>\n",
       "      <td>0.948886</td>\n",
       "      <td>4.579309</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2.403951</td>\n",
       "      <td>0.785176</td>\n",
       "      <td>3.650089</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>8.795585</td>\n",
       "      <td>0.514234</td>\n",
       "      <td>3.080272</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>1.185260</td>\n",
       "      <td>0.607545</td>\n",
       "      <td>4.878339</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>8.491984</td>\n",
       "      <td>0.065052</td>\n",
       "      <td>4.757996</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   respondent_id  trip_id  product_id     price  brand_strength  \\\n",
       "0              0        0          13  2.911052        0.948886   \n",
       "1              0        0           5  2.403951        0.785176   \n",
       "2              0        0           7  8.795585        0.514234   \n",
       "3              0        0          10  1.185260        0.607545   \n",
       "4              0        0          12  8.491984        0.065052   \n",
       "\n",
       "   quality_score  group  choice  \n",
       "0       4.579309      0       0  \n",
       "1       3.650089      0       0  \n",
       "2       3.080272      0       0  \n",
       "3       4.878339      0       1  \n",
       "4       4.757996      0       0  "
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "respondents_data_path = r\"C:\\Users\\HP\\OneDrive\\Escritorio\\David Guzzi\\Github\\Python-Projects\\astrea\\synthetic_choice_data.csv\"\n",
    "respondents_data = pd.read_csv(respondents_data_path, delimiter=\",\")\n",
    "respondents_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 75000 entries, 0 to 74999\n",
      "Data columns (total 8 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   respondent_id   75000 non-null  int64  \n",
      " 1   trip_id         75000 non-null  int64  \n",
      " 2   product_id      75000 non-null  int64  \n",
      " 3   price           75000 non-null  float64\n",
      " 4   brand_strength  75000 non-null  float64\n",
      " 5   quality_score   75000 non-null  float64\n",
      " 6   group           75000 non-null  int64  \n",
      " 7   choice          75000 non-null  int64  \n",
      "dtypes: float64(3), int64(5)\n",
      "memory usage: 4.6 MB\n"
     ]
    }
   ],
   "source": [
    "respondents_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>respondent_id</th>\n",
       "      <th>trip_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>price</th>\n",
       "      <th>brand_strength</th>\n",
       "      <th>quality_score</th>\n",
       "      <th>group</th>\n",
       "      <th>choice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [respondent_id, trip_id, product_id, price, brand_strength, quality_score, group, choice]\n",
       "Index: []"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "respondents_data[respondents_data.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Column: respondent_id\n",
      "Total unique: 1500\n",
      "Unique values: [   0    1    2 ... 1497 1498 1499]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Column: trip_id\n",
      "Total unique: 10\n",
      "Unique values: [0 1 2 3 4 5 6 7 8 9]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Column: product_id\n",
      "Total unique: 20\n",
      "Unique values: [13  5  7 10 12  0  3  1 19 15 18  9 17 14 16  8  2 11  6  4]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Column: group\n",
      "Total unique: 2\n",
      "Unique values: [0 1]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Column: choice\n",
      "Total unique: 2\n",
      "Unique values: [0 1]\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in ['respondent_id', 'trip_id', 'product_id', 'group', 'choice']:\n",
    "    print(f\"\\nColumn: {i}\")\n",
    "    print(f\"Total unique: {respondents_data[i].nunique()}\")\n",
    "    print(f\"Unique values: {respondents_data[i].unique()}\")\n",
    "    print(\"-\" * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Unique values for total observations per respondent:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[50]\n",
      "\n",
      "Unique values for unique trips per respondent:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[10]\n"
     ]
    }
   ],
   "source": [
    "respondent_stats = respondents_data.groupby('respondent_id')['trip_id'].nunique().reset_index()\n",
    "respondent_stats['total_observations'] = respondents_data.groupby('respondent_id').size().values\n",
    "\n",
    "print(\"\\nUnique values for total observations per respondent:\")\n",
    "print(\"-\" * 100)\n",
    "print(respondent_stats['total_observations'].unique())\n",
    "\n",
    "print(\"\\nUnique values for unique trips per respondent:\")\n",
    "print(\"-\" * 100)\n",
    "print(respondent_stats['trip_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total unique respondents: 1500\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Unique respondents in Group 0: 738\n",
      "Unique respondents in Group 1: 762\n"
     ]
    }
   ],
   "source": [
    "total_respondents = respondents_data['respondent_id'].nunique()\n",
    "group_0_respondents = respondents_data[respondents_data[\"group\"] == 0]['respondent_id'].nunique()\n",
    "group_1_respondents = respondents_data[respondents_data[\"group\"] == 1]['respondent_id'].nunique()\n",
    "\n",
    "print(f\"\\nTotal unique respondents: {total_respondents}\")\n",
    "print(\"-\" * 100)\n",
    "print(f\"Unique respondents in Group 0: {group_0_respondents}\")\n",
    "print(f\"Unique respondents in Group 1: {group_1_respondents}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>respondent_id</th>\n",
       "      <th>trip_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>price</th>\n",
       "      <th>brand_strength</th>\n",
       "      <th>quality_score</th>\n",
       "      <th>group</th>\n",
       "      <th>choice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>2.911052</td>\n",
       "      <td>0.948886</td>\n",
       "      <td>4.579309</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2.403951</td>\n",
       "      <td>0.785176</td>\n",
       "      <td>3.650089</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>8.795585</td>\n",
       "      <td>0.514234</td>\n",
       "      <td>3.080272</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>1.185260</td>\n",
       "      <td>0.607545</td>\n",
       "      <td>4.878339</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>8.491984</td>\n",
       "      <td>0.065052</td>\n",
       "      <td>4.757996</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.370861</td>\n",
       "      <td>0.611853</td>\n",
       "      <td>1.488153</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6.387926</td>\n",
       "      <td>0.366362</td>\n",
       "      <td>4.637282</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2.403951</td>\n",
       "      <td>0.785176</td>\n",
       "      <td>3.650089</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>2.911052</td>\n",
       "      <td>0.948886</td>\n",
       "      <td>4.579309</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>8.795585</td>\n",
       "      <td>0.514234</td>\n",
       "      <td>3.080272</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>2.650641</td>\n",
       "      <td>0.808397</td>\n",
       "      <td>4.687497</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4.370861</td>\n",
       "      <td>0.611853</td>\n",
       "      <td>1.488153</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>9.556429</td>\n",
       "      <td>0.139494</td>\n",
       "      <td>2.980708</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>3.621062</td>\n",
       "      <td>0.440152</td>\n",
       "      <td>2.301321</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>8.491984</td>\n",
       "      <td>0.065052</td>\n",
       "      <td>4.757996</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>4.887505</td>\n",
       "      <td>0.684233</td>\n",
       "      <td>1.180909</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>7.372653</td>\n",
       "      <td>0.046450</td>\n",
       "      <td>1.739418</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>5.722808</td>\n",
       "      <td>0.097672</td>\n",
       "      <td>1.783931</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>2.636425</td>\n",
       "      <td>0.965632</td>\n",
       "      <td>3.391600</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>3.738180</td>\n",
       "      <td>0.304614</td>\n",
       "      <td>1.353970</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>2.636425</td>\n",
       "      <td>0.965632</td>\n",
       "      <td>3.391600</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>2.911052</td>\n",
       "      <td>0.948886</td>\n",
       "      <td>4.579309</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>2.650641</td>\n",
       "      <td>0.808397</td>\n",
       "      <td>4.687497</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>7.372653</td>\n",
       "      <td>0.046450</td>\n",
       "      <td>1.739418</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>6.410035</td>\n",
       "      <td>0.592415</td>\n",
       "      <td>3.186841</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>1.185260</td>\n",
       "      <td>0.607545</td>\n",
       "      <td>4.878339</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>6.410035</td>\n",
       "      <td>0.592415</td>\n",
       "      <td>3.186841</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>9.556429</td>\n",
       "      <td>0.139494</td>\n",
       "      <td>2.980708</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>7.372653</td>\n",
       "      <td>0.046450</td>\n",
       "      <td>1.739418</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4.370861</td>\n",
       "      <td>0.611853</td>\n",
       "      <td>1.488153</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>7.587945</td>\n",
       "      <td>0.292145</td>\n",
       "      <td>1.137554</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>1.185260</td>\n",
       "      <td>0.607545</td>\n",
       "      <td>4.878339</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>2.911052</td>\n",
       "      <td>0.948886</td>\n",
       "      <td>4.579309</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>6.410035</td>\n",
       "      <td>0.592415</td>\n",
       "      <td>3.186841</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>7.372653</td>\n",
       "      <td>0.046450</td>\n",
       "      <td>1.739418</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>19</td>\n",
       "      <td>3.621062</td>\n",
       "      <td>0.440152</td>\n",
       "      <td>2.301321</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>2.636425</td>\n",
       "      <td>0.965632</td>\n",
       "      <td>3.391600</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>8.491984</td>\n",
       "      <td>0.065052</td>\n",
       "      <td>4.757996</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>6.410035</td>\n",
       "      <td>0.592415</td>\n",
       "      <td>3.186841</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>7.372653</td>\n",
       "      <td>0.046450</td>\n",
       "      <td>1.739418</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>8.795585</td>\n",
       "      <td>0.514234</td>\n",
       "      <td>3.080272</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>4.370861</td>\n",
       "      <td>0.611853</td>\n",
       "      <td>1.488153</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>9.729189</td>\n",
       "      <td>0.170524</td>\n",
       "      <td>4.100531</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>2.636425</td>\n",
       "      <td>0.965632</td>\n",
       "      <td>3.391600</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>18</td>\n",
       "      <td>4.887505</td>\n",
       "      <td>0.684233</td>\n",
       "      <td>1.180909</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>9.556429</td>\n",
       "      <td>0.139494</td>\n",
       "      <td>2.980708</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>7.372653</td>\n",
       "      <td>0.046450</td>\n",
       "      <td>1.739418</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>9.729189</td>\n",
       "      <td>0.170524</td>\n",
       "      <td>4.100531</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>1.522753</td>\n",
       "      <td>0.199674</td>\n",
       "      <td>2.246844</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>8.795585</td>\n",
       "      <td>0.514234</td>\n",
       "      <td>3.080272</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    respondent_id  trip_id  product_id     price  brand_strength  \\\n",
       "0               0        0          13  2.911052        0.948886   \n",
       "1               0        0           5  2.403951        0.785176   \n",
       "2               0        0           7  8.795585        0.514234   \n",
       "3               0        0          10  1.185260        0.607545   \n",
       "4               0        0          12  8.491984        0.065052   \n",
       "5               0        1           0  4.370861        0.611853   \n",
       "6               0        1           3  6.387926        0.366362   \n",
       "7               0        1           5  2.403951        0.785176   \n",
       "8               0        1          13  2.911052        0.948886   \n",
       "9               0        1           7  8.795585        0.514234   \n",
       "14              0        2          15  2.650641        0.808397   \n",
       "13              0        2           0  4.370861        0.611853   \n",
       "10              0        2           1  9.556429        0.139494   \n",
       "11              0        2          19  3.621062        0.440152   \n",
       "12              0        2          12  8.491984        0.065052   \n",
       "15              0        3          18  4.887505        0.684233   \n",
       "16              0        3           9  7.372653        0.046450   \n",
       "17              0        3          17  5.722808        0.097672   \n",
       "18              0        3          14  2.636425        0.965632   \n",
       "19              0        3          16  3.738180        0.304614   \n",
       "23              0        4          14  2.636425        0.965632   \n",
       "22              0        4          13  2.911052        0.948886   \n",
       "24              0        4          15  2.650641        0.808397   \n",
       "20              0        4           9  7.372653        0.046450   \n",
       "21              0        4           8  6.410035        0.592415   \n",
       "25              0        5          10  1.185260        0.607545   \n",
       "26              0        5           8  6.410035        0.592415   \n",
       "27              0        5           1  9.556429        0.139494   \n",
       "28              0        5           9  7.372653        0.046450   \n",
       "29              0        5           0  4.370861        0.611853   \n",
       "30              0        6           2  7.587945        0.292145   \n",
       "31              0        6          10  1.185260        0.607545   \n",
       "32              0        6          13  2.911052        0.948886   \n",
       "33              0        6           8  6.410035        0.592415   \n",
       "34              0        6           9  7.372653        0.046450   \n",
       "39              0        7          19  3.621062        0.440152   \n",
       "38              0        7          14  2.636425        0.965632   \n",
       "36              0        7          12  8.491984        0.065052   \n",
       "35              0        7           8  6.410035        0.592415   \n",
       "37              0        7           9  7.372653        0.046450   \n",
       "40              0        8           7  8.795585        0.514234   \n",
       "41              0        8           0  4.370861        0.611853   \n",
       "42              0        8          11  9.729189        0.170524   \n",
       "43              0        8          14  2.636425        0.965632   \n",
       "44              0        8          18  4.887505        0.684233   \n",
       "48              0        9           1  9.556429        0.139494   \n",
       "45              0        9           9  7.372653        0.046450   \n",
       "46              0        9          11  9.729189        0.170524   \n",
       "47              0        9           6  1.522753        0.199674   \n",
       "49              0        9           7  8.795585        0.514234   \n",
       "\n",
       "    quality_score  group  choice  \n",
       "0        4.579309      0       0  \n",
       "1        3.650089      0       0  \n",
       "2        3.080272      0       0  \n",
       "3        4.878339      0       1  \n",
       "4        4.757996      0       0  \n",
       "5        1.488153      0       0  \n",
       "6        4.637282      0       0  \n",
       "7        3.650089      0       0  \n",
       "8        4.579309      0       1  \n",
       "9        3.080272      0       0  \n",
       "14       4.687497      0       1  \n",
       "13       1.488153      0       0  \n",
       "10       2.980708      0       0  \n",
       "11       2.301321      0       0  \n",
       "12       4.757996      0       0  \n",
       "15       1.180909      0       0  \n",
       "16       1.739418      0       0  \n",
       "17       1.783931      0       0  \n",
       "18       3.391600      0       1  \n",
       "19       1.353970      0       0  \n",
       "23       3.391600      0       0  \n",
       "22       4.579309      0       1  \n",
       "24       4.687497      0       0  \n",
       "20       1.739418      0       0  \n",
       "21       3.186841      0       0  \n",
       "25       4.878339      0       1  \n",
       "26       3.186841      0       0  \n",
       "27       2.980708      0       0  \n",
       "28       1.739418      0       0  \n",
       "29       1.488153      0       0  \n",
       "30       1.137554      0       0  \n",
       "31       4.878339      0       1  \n",
       "32       4.579309      0       0  \n",
       "33       3.186841      0       0  \n",
       "34       1.739418      0       0  \n",
       "39       2.301321      0       0  \n",
       "38       3.391600      0       1  \n",
       "36       4.757996      0       0  \n",
       "35       3.186841      0       0  \n",
       "37       1.739418      0       0  \n",
       "40       3.080272      0       0  \n",
       "41       1.488153      0       0  \n",
       "42       4.100531      0       0  \n",
       "43       3.391600      0       1  \n",
       "44       1.180909      0       0  \n",
       "48       2.980708      0       0  \n",
       "45       1.739418      0       0  \n",
       "46       4.100531      0       0  \n",
       "47       2.246844      0       1  \n",
       "49       3.080272      0       0  "
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "respondents_data[respondents_data[\"respondent_id\"] == 0].sort_values(by='trip_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>respondent_id</th>\n",
       "      <th>trip_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>price</th>\n",
       "      <th>brand_strength</th>\n",
       "      <th>quality_score</th>\n",
       "      <th>group</th>\n",
       "      <th>choice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>5.722808</td>\n",
       "      <td>0.097672</td>\n",
       "      <td>1.783931</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6.387926</td>\n",
       "      <td>0.366362</td>\n",
       "      <td>4.637282</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>8.491984</td>\n",
       "      <td>0.065052</td>\n",
       "      <td>4.757996</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>2.650641</td>\n",
       "      <td>0.808397</td>\n",
       "      <td>4.687497</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2.403951</td>\n",
       "      <td>0.785176</td>\n",
       "      <td>3.650089</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>7.372653</td>\n",
       "      <td>0.046450</td>\n",
       "      <td>1.739418</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.370861</td>\n",
       "      <td>0.611853</td>\n",
       "      <td>1.488153</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>3.621062</td>\n",
       "      <td>0.440152</td>\n",
       "      <td>2.301321</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7.587945</td>\n",
       "      <td>0.292145</td>\n",
       "      <td>1.137554</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6.387926</td>\n",
       "      <td>0.366362</td>\n",
       "      <td>4.637282</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>3.738180</td>\n",
       "      <td>0.304614</td>\n",
       "      <td>1.353970</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>5.722808</td>\n",
       "      <td>0.097672</td>\n",
       "      <td>1.783931</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>3.621062</td>\n",
       "      <td>0.440152</td>\n",
       "      <td>2.301321</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>2.911052</td>\n",
       "      <td>0.948886</td>\n",
       "      <td>4.579309</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>9.556429</td>\n",
       "      <td>0.139494</td>\n",
       "      <td>2.980708</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>4.887505</td>\n",
       "      <td>0.684233</td>\n",
       "      <td>1.180909</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>2.636425</td>\n",
       "      <td>0.965632</td>\n",
       "      <td>3.391600</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>2.650641</td>\n",
       "      <td>0.808397</td>\n",
       "      <td>4.687497</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>1.185260</td>\n",
       "      <td>0.607545</td>\n",
       "      <td>4.878339</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1.522753</td>\n",
       "      <td>0.199674</td>\n",
       "      <td>2.246844</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>2.650641</td>\n",
       "      <td>0.808397</td>\n",
       "      <td>4.687497</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>3.738180</td>\n",
       "      <td>0.304614</td>\n",
       "      <td>1.353970</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1.522753</td>\n",
       "      <td>0.199674</td>\n",
       "      <td>2.246844</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "      <td>5.722808</td>\n",
       "      <td>0.097672</td>\n",
       "      <td>1.783931</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>1.185260</td>\n",
       "      <td>0.607545</td>\n",
       "      <td>4.878339</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>9.556429</td>\n",
       "      <td>0.139494</td>\n",
       "      <td>2.980708</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>5.722808</td>\n",
       "      <td>0.097672</td>\n",
       "      <td>1.783931</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>8.491984</td>\n",
       "      <td>0.065052</td>\n",
       "      <td>4.757996</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>1.185260</td>\n",
       "      <td>0.607545</td>\n",
       "      <td>4.878339</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4.370861</td>\n",
       "      <td>0.611853</td>\n",
       "      <td>1.488153</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>6.410035</td>\n",
       "      <td>0.592415</td>\n",
       "      <td>3.186841</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "      <td>5.722808</td>\n",
       "      <td>0.097672</td>\n",
       "      <td>1.783931</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>4.370861</td>\n",
       "      <td>0.611853</td>\n",
       "      <td>1.488153</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>1.185260</td>\n",
       "      <td>0.607545</td>\n",
       "      <td>4.878339</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>2.403951</td>\n",
       "      <td>0.785176</td>\n",
       "      <td>3.650089</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>6.410035</td>\n",
       "      <td>0.592415</td>\n",
       "      <td>3.186841</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>2.636425</td>\n",
       "      <td>0.965632</td>\n",
       "      <td>3.391600</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>2.404168</td>\n",
       "      <td>0.456070</td>\n",
       "      <td>2.035120</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>8.795585</td>\n",
       "      <td>0.514234</td>\n",
       "      <td>3.080272</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>17</td>\n",
       "      <td>5.722808</td>\n",
       "      <td>0.097672</td>\n",
       "      <td>1.783931</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>7.372653</td>\n",
       "      <td>0.046450</td>\n",
       "      <td>1.739418</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>7.587945</td>\n",
       "      <td>0.292145</td>\n",
       "      <td>1.137554</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>8.795585</td>\n",
       "      <td>0.514234</td>\n",
       "      <td>3.080272</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>19</td>\n",
       "      <td>3.621062</td>\n",
       "      <td>0.440152</td>\n",
       "      <td>2.301321</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>2.636425</td>\n",
       "      <td>0.965632</td>\n",
       "      <td>3.391600</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>15</td>\n",
       "      <td>2.650641</td>\n",
       "      <td>0.808397</td>\n",
       "      <td>4.687497</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>8.795585</td>\n",
       "      <td>0.514234</td>\n",
       "      <td>3.080272</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>1.522753</td>\n",
       "      <td>0.199674</td>\n",
       "      <td>2.246844</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>6.387926</td>\n",
       "      <td>0.366362</td>\n",
       "      <td>4.637282</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>9.729189</td>\n",
       "      <td>0.170524</td>\n",
       "      <td>4.100531</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     respondent_id  trip_id  product_id     price  brand_strength  \\\n",
       "100              2        0          17  5.722808        0.097672   \n",
       "101              2        0           3  6.387926        0.366362   \n",
       "102              2        0          12  8.491984        0.065052   \n",
       "103              2        0          15  2.650641        0.808397   \n",
       "104              2        0           5  2.403951        0.785176   \n",
       "105              2        1           9  7.372653        0.046450   \n",
       "106              2        1           0  4.370861        0.611853   \n",
       "107              2        1          19  3.621062        0.440152   \n",
       "108              2        1           2  7.587945        0.292145   \n",
       "109              2        1           3  6.387926        0.366362   \n",
       "114              2        2          16  3.738180        0.304614   \n",
       "113              2        2          17  5.722808        0.097672   \n",
       "110              2        2          19  3.621062        0.440152   \n",
       "111              2        2          13  2.911052        0.948886   \n",
       "112              2        2           1  9.556429        0.139494   \n",
       "115              2        3          18  4.887505        0.684233   \n",
       "116              2        3          14  2.636425        0.965632   \n",
       "117              2        3          15  2.650641        0.808397   \n",
       "118              2        3          10  1.185260        0.607545   \n",
       "119              2        3           6  1.522753        0.199674   \n",
       "123              2        4          15  2.650641        0.808397   \n",
       "122              2        4          16  3.738180        0.304614   \n",
       "124              2        4           6  1.522753        0.199674   \n",
       "120              2        4          17  5.722808        0.097672   \n",
       "121              2        4          10  1.185260        0.607545   \n",
       "125              2        5           1  9.556429        0.139494   \n",
       "126              2        5          17  5.722808        0.097672   \n",
       "127              2        5          12  8.491984        0.065052   \n",
       "128              2        5          10  1.185260        0.607545   \n",
       "129              2        5           0  4.370861        0.611853   \n",
       "130              2        6           8  6.410035        0.592415   \n",
       "131              2        6          17  5.722808        0.097672   \n",
       "132              2        6           0  4.370861        0.611853   \n",
       "133              2        6          10  1.185260        0.607545   \n",
       "134              2        6           5  2.403951        0.785176   \n",
       "139              2        7           8  6.410035        0.592415   \n",
       "138              2        7          14  2.636425        0.965632   \n",
       "136              2        7           4  2.404168        0.456070   \n",
       "135              2        7           7  8.795585        0.514234   \n",
       "137              2        7          17  5.722808        0.097672   \n",
       "140              2        8           9  7.372653        0.046450   \n",
       "141              2        8           2  7.587945        0.292145   \n",
       "142              2        8           7  8.795585        0.514234   \n",
       "143              2        8          19  3.621062        0.440152   \n",
       "144              2        8          14  2.636425        0.965632   \n",
       "148              2        9          15  2.650641        0.808397   \n",
       "145              2        9           7  8.795585        0.514234   \n",
       "146              2        9           6  1.522753        0.199674   \n",
       "147              2        9           3  6.387926        0.366362   \n",
       "149              2        9          11  9.729189        0.170524   \n",
       "\n",
       "     quality_score  group  choice  \n",
       "100       1.783931      1       0  \n",
       "101       4.637282      1       0  \n",
       "102       4.757996      1       0  \n",
       "103       4.687497      1       1  \n",
       "104       3.650089      1       0  \n",
       "105       1.739418      1       0  \n",
       "106       1.488153      1       0  \n",
       "107       2.301321      1       0  \n",
       "108       1.137554      1       0  \n",
       "109       4.637282      1       1  \n",
       "114       1.353970      1       0  \n",
       "113       1.783931      1       0  \n",
       "110       2.301321      1       0  \n",
       "111       4.579309      1       1  \n",
       "112       2.980708      1       0  \n",
       "115       1.180909      1       0  \n",
       "116       3.391600      1       0  \n",
       "117       4.687497      1       0  \n",
       "118       4.878339      1       1  \n",
       "119       2.246844      1       0  \n",
       "123       4.687497      1       0  \n",
       "122       1.353970      1       0  \n",
       "124       2.246844      1       0  \n",
       "120       1.783931      1       0  \n",
       "121       4.878339      1       1  \n",
       "125       2.980708      1       0  \n",
       "126       1.783931      1       0  \n",
       "127       4.757996      1       0  \n",
       "128       4.878339      1       1  \n",
       "129       1.488153      1       0  \n",
       "130       3.186841      1       0  \n",
       "131       1.783931      1       0  \n",
       "132       1.488153      1       0  \n",
       "133       4.878339      1       1  \n",
       "134       3.650089      1       0  \n",
       "139       3.186841      1       1  \n",
       "138       3.391600      1       0  \n",
       "136       2.035120      1       0  \n",
       "135       3.080272      1       0  \n",
       "137       1.783931      1       0  \n",
       "140       1.739418      1       0  \n",
       "141       1.137554      1       0  \n",
       "142       3.080272      1       0  \n",
       "143       2.301321      1       0  \n",
       "144       3.391600      1       1  \n",
       "148       4.687497      1       1  \n",
       "145       3.080272      1       0  \n",
       "146       2.246844      1       0  \n",
       "147       4.637282      1       0  \n",
       "149       4.100531      1       0  "
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "respondents_data[respondents_data[\"respondent_id\"] == 2].sort_values(by='trip_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"admonition tip alert alert-info\">\n",
    "<p class=\"first admonition-title\" style=\"font-weight: bold;\">Dataset Overview</p>\n",
    "<p class=\"last\">\n",
    "From the dataset observation, the following points can be noted:\n",
    "\n",
    "- The dataset contains 8 columns:  \n",
    "  i) <strong>respondent_id</strong> (survey respondent),  \n",
    "  ii) <strong>trip_id</strong> (subsets of items),  \n",
    "  iii) <strong>product_id</strong> (item),  \n",
    "  iv) <strong>price</strong>,  \n",
    "  v) <strong>brand_strength</strong>,  \n",
    "  vi) <strong>quality_score</strong>,  \n",
    "  vii) <strong>group</strong>,  \n",
    "  viii) <strong>choice</strong> (purchase decision for an item within trip_id).\n",
    "\n",
    "- The dataset has <strong>75,000 observations</strong> with correctly formatted columns, no missing data, and no duplicate records. \n",
    "\n",
    "- The survey was conducted on <strong>1,500 respondents</strong>, each required to choose <strong>10 product_id</strong>. Since only one product_id must be selected per trip_id (as choice is a binary variable) and each respondent has <strong>10 unique trip_id</strong>, the <strong>total number of records per respondent is 50</strong>.\n",
    "\n",
    "- Since <strong>choice is a binary variable</strong>, under this scenario, there would be <strong>no difference</strong> between the results (coefficients) produced by a Logit model and an MNL Logit model. \n",
    "    \n",
    "- There are <strong>2 groups</strong>:  \n",
    "  - <strong>Group 0:</strong> 738 respondents.  \n",
    "  - <strong>Group 1:</strong> 762 respondents.\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Finally, before interpreting the coefficients, an attempt is made to generate them using the provided dataset and the statsmodels library.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.276433\n",
      "         Iterations 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable</th>\n",
       "      <th>coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>const</td>\n",
       "      <td>-3.289498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>price</td>\n",
       "      <td>-0.584335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>brand_strength</td>\n",
       "      <td>0.310713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>quality_score</td>\n",
       "      <td>1.200612</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         variable  coefficient\n",
       "0           const    -3.289498\n",
       "1           price    -0.584335\n",
       "2  brand_strength     0.310713\n",
       "3   quality_score     1.200612"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = respondents_data[['price', 'brand_strength', 'quality_score']]\n",
    "y = respondents_data['choice']\n",
    "\n",
    "X = sm.add_constant(x)\n",
    "\n",
    "model = sm.MNLogit(y, X)\n",
    "results = model.fit()\n",
    "coefs = pd.DataFrame(results.params).reset_index()\n",
    "coefs.columns = ['variable', 'coefficient']\n",
    "coefs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The confirmation of the coefficient calculation method, along with the previous exploratory analysis, allows us to make more appropriate comments regarding the obtained coefficients. Before proceeding, we analytically specify the model used.  \n",
    "\n",
    "This model enables us to measure the effect of a change in the explanatory variable $x_i$ on the probability of the analyzed event occurring. This effect arises from the derivative of $Pr[yᵢ = j \\mid .]$ with respect to $x_i$:  \n",
    "\n",
    "$\\frac{\\partial Pr[yᵢ = j \\mid .]}{\\partial xᵢ} = Pr[yᵢ = j \\mid .] \\left\\{ \\alpha_j - \\sum_{l=1}^{J-1} \\alpha_l Pr[yᵢ = l \\mid .] \\right\\}$\n",
    "\n",
    "The sign of this derivative depends not only on the sign of the coefficient associated with $x_i$ but also on the sign of the term within the brackets. Therefore, the coefficients of the MNL Logit model are not directly interpretable, as they represent the impact of each variable on the log-odds of the event occurring.\n",
    "\n",
    "One way to interpret these coefficients is by calculating the average marginal effects, which show the change in probability—evaluated at the mean values of the covariates—for a one-unit change in each explanatory variable, holding others constant. We proceed to compute them next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>MNLogit Marginal Effects</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th> <td>choice</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>         <td>dydx</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>At:</th>             <td>mean</td> \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "     <th>choice=0</th>       <th>dy/dx</th>    <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>price</th>          <td>    0.0380</td> <td>    0.001</td> <td>   70.298</td> <td> 0.000</td> <td>    0.037</td> <td>    0.039</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>brand_strength</th> <td>   -0.0202</td> <td>    0.004</td> <td>   -5.560</td> <td> 0.000</td> <td>   -0.027</td> <td>   -0.013</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>quality_score</th>  <td>   -0.0781</td> <td>    0.001</td> <td>  -67.903</td> <td> 0.000</td> <td>   -0.080</td> <td>   -0.076</td>\n",
       "</tr>\n",
       "<tr>\n",
       "     <th>choice=1</th>       <th>dy/dx</th>    <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>price</th>          <td>   -0.0380</td> <td>    0.001</td> <td>  -70.298</td> <td> 0.000</td> <td>   -0.039</td> <td>   -0.037</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>brand_strength</th> <td>    0.0202</td> <td>    0.004</td> <td>    5.560</td> <td> 0.000</td> <td>    0.013</td> <td>    0.027</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>quality_score</th>  <td>    0.0781</td> <td>    0.001</td> <td>   67.903</td> <td> 0.000</td> <td>    0.076</td> <td>    0.080</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}  &     choice      \\\\\n",
       "\\textbf{Method:}         &      dydx       \\\\\n",
       "\\textbf{At:}             &      mean       \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{ccccccc}\n",
       "   \\textbf{choice=0}     & \\textbf{dy/dx} & \\textbf{std err} & \\textbf{z} & \\textbf{P$> |$z$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "\\textbf{price}           &       0.0380   &        0.001     &    70.298  &         0.000        &        0.037    &        0.039     \\\\\n",
       "\\textbf{brand\\_strength} &      -0.0202   &        0.004     &    -5.560  &         0.000        &       -0.027    &       -0.013     \\\\\n",
       "\\textbf{quality\\_score}  &      -0.0781   &        0.001     &   -67.903  &         0.000        &       -0.080    &       -0.076     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{ccccccc}\n",
       "   \\textbf{choice=1}     & \\textbf{dy/dx} & \\textbf{std err} & \\textbf{z} & \\textbf{P$> |$z$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "\\textbf{price}           &      -0.0380   &        0.001     &   -70.298  &         0.000        &       -0.039    &       -0.037     \\\\\n",
       "\\textbf{brand\\_strength} &       0.0202   &        0.004     &     5.560  &         0.000        &        0.013    &        0.027     \\\\\n",
       "\\textbf{quality\\_score}  &       0.0781   &        0.001     &    67.903  &         0.000        &        0.076    &        0.080     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{MNLogit Marginal Effects}\n",
       "\\end{center}"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "       MNLogit Marginal Effects      \n",
       "=====================================\n",
       "Dep. Variable:                 choice\n",
       "Method:                          dydx\n",
       "At:                              mean\n",
       "==================================================================================\n",
       "      choice=0      dy/dx    std err          z      P>|z|      [0.025      0.975]\n",
       "----------------------------------------------------------------------------------\n",
       "price              0.0380      0.001     70.298      0.000       0.037       0.039\n",
       "brand_strength    -0.0202      0.004     -5.560      0.000      -0.027      -0.013\n",
       "quality_score     -0.0781      0.001    -67.903      0.000      -0.080      -0.076\n",
       "----------------------------------------------------------------------------------\n",
       "      choice=1      dy/dx    std err          z      P>|z|      [0.025      0.975]\n",
       "----------------------------------------------------------------------------------\n",
       "price             -0.0380      0.001    -70.298      0.000      -0.039      -0.037\n",
       "brand_strength     0.0202      0.004      5.560      0.000       0.013       0.027\n",
       "quality_score      0.0781      0.001     67.903      0.000       0.076       0.080\n",
       "==================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "margins = results.get_margeff(at='mean')\n",
    "margins.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"admonition tip alert alert-info\">\n",
    "<p class=\"first admonition-title\" style=\"font-weight: bold;\">Coefficients interpretation</p>\n",
    "<p class=\"last\">\n",
    "\n",
    "In this context, we can interpret the marginal effects as follows:\n",
    "\n",
    "- **Price** (-0.0380): A higher price decreases the probability of a product being chosen. Specifically, a one-unit increase in price reduces the probability of choice by 3.80 percentage points, on average.\n",
    "\n",
    "- **Brand Strength** (0.0202): A stronger brand increases the probability of selection. A one-unit increase in brand strength raises the probability of choice by 2.02 percentage points, on average.\n",
    "\n",
    "- **Quality Score** (0.0781): A higher quality perception significantly increases the likelihood of selection. A one-unit increase in quality score leads to a 7.81 percentage point rise in the probability of choice.\n",
    "\n",
    "Overall, consumers prefer lower prices, stronger brands, and higher perceived quality when making their purchasing decisions.\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, using the estimated coefficients, the **choice probabilities for each product_id** are calculated **for every represent_id and trip_id** in the analyzed dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>respondent_id</th>\n",
       "      <th>trip_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>price</th>\n",
       "      <th>brand_strength</th>\n",
       "      <th>quality_score</th>\n",
       "      <th>group</th>\n",
       "      <th>choice</th>\n",
       "      <th>const</th>\n",
       "      <th>exp_utilities</th>\n",
       "      <th>predicted_choice_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>2.911052</td>\n",
       "      <td>0.948886</td>\n",
       "      <td>4.579309</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.230619</td>\n",
       "      <td>0.200402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2.403951</td>\n",
       "      <td>0.785176</td>\n",
       "      <td>3.650089</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.934350</td>\n",
       "      <td>0.083943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>8.795585</td>\n",
       "      <td>0.514234</td>\n",
       "      <td>3.080272</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.010347</td>\n",
       "      <td>0.000930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>1.185260</td>\n",
       "      <td>0.607545</td>\n",
       "      <td>4.878339</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.874885</td>\n",
       "      <td>0.707489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>8.491984</td>\n",
       "      <td>0.065052</td>\n",
       "      <td>4.757996</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.080545</td>\n",
       "      <td>0.007236</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   respondent_id  trip_id  product_id     price  brand_strength  \\\n",
       "0              0        0          13  2.911052        0.948886   \n",
       "1              0        0           5  2.403951        0.785176   \n",
       "2              0        0           7  8.795585        0.514234   \n",
       "3              0        0          10  1.185260        0.607545   \n",
       "4              0        0          12  8.491984        0.065052   \n",
       "\n",
       "   quality_score  group  choice  const  exp_utilities  predicted_choice_prob  \n",
       "0       4.579309      0       0    1.0       2.230619               0.200402  \n",
       "1       3.650089      0       0    1.0       0.934350               0.083943  \n",
       "2       3.080272      0       0    1.0       0.010347               0.000930  \n",
       "3       4.878339      0       1    1.0       7.874885               0.707489  \n",
       "4       4.757996      0       0    1.0       0.080545               0.007236  "
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "respondents_data[\"const\"] = 1.0\n",
    "\n",
    "# Compute utility scores.\n",
    "utilities = (\n",
    "respondents_data[\"const\"] * coefs['coefficient'][0] +\n",
    "respondents_data[\"price\"] * coefs['coefficient'][1] +\n",
    "respondents_data[\"brand_strength\"] * coefs['coefficient'][2] +\n",
    "respondents_data[\"quality_score\"] * coefs['coefficient'][3]\n",
    ")\n",
    "\n",
    "# Apply softmax transformation within each respondent-trip group.\n",
    "respondents_data[\"exp_utilities\"] = np.exp(utilities)\n",
    "respondents_data[\"predicted_choice_prob\"] = respondents_data.groupby([\"respondent_id\", \"trip_id\"])[\"exp_utilities\"].transform(lambda x: x / x.sum())\n",
    "respondents_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, we should expect that for records with `choice = 1`, the probability of selection should be high (possibly the highest within each `trip_id`). This can be summarized in the following chart:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "respondents_data.groupby(\"choice\")[\"predicted_choice_prob\"].plot.hist(\n",
    "    alpha=0.5, bins=30, legend=True, density=True\n",
    ")\n",
    "plt.xlabel(\"Choice Probabilities\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.title(\"Distribution of Predicted Choice Probabilities by Choice Outcome\")\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "plt.legend(title=\"Choice\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyzing the dataset output, we can observe that cases with low selection probability when `choice = 1` are mainly due to the presence of products within the same `trip_id` that have higher values of `brand_strength` and `quality_score` or lower `price`. This impacts the probability calculation. The following is an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>respondent_id</th>\n",
       "      <th>trip_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>price</th>\n",
       "      <th>brand_strength</th>\n",
       "      <th>quality_score</th>\n",
       "      <th>group</th>\n",
       "      <th>choice</th>\n",
       "      <th>const</th>\n",
       "      <th>exp_utilities</th>\n",
       "      <th>predicted_choice_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>4.370861</td>\n",
       "      <td>0.611853</td>\n",
       "      <td>1.488153</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.020926</td>\n",
       "      <td>0.163488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>18</td>\n",
       "      <td>4.887505</td>\n",
       "      <td>0.684233</td>\n",
       "      <td>1.180909</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.010943</td>\n",
       "      <td>0.085495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>8.491984</td>\n",
       "      <td>0.065052</td>\n",
       "      <td>4.757996</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.080545</td>\n",
       "      <td>0.629254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>8.795585</td>\n",
       "      <td>0.514234</td>\n",
       "      <td>3.080272</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.010347</td>\n",
       "      <td>0.080834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>9.556429</td>\n",
       "      <td>0.139494</td>\n",
       "      <td>2.980708</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.005239</td>\n",
       "      <td>0.040929</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    respondent_id  trip_id  product_id     price  brand_strength  \\\n",
       "85              1        7           0  4.370861        0.611853   \n",
       "86              1        7          18  4.887505        0.684233   \n",
       "87              1        7          12  8.491984        0.065052   \n",
       "88              1        7           7  8.795585        0.514234   \n",
       "89              1        7           1  9.556429        0.139494   \n",
       "\n",
       "    quality_score  group  choice  const  exp_utilities  predicted_choice_prob  \n",
       "85       1.488153      0       0    1.0       0.020926               0.163488  \n",
       "86       1.180909      0       1    1.0       0.010943               0.085495  \n",
       "87       4.757996      0       0    1.0       0.080545               0.629254  \n",
       "88       3.080272      0       0    1.0       0.010347               0.080834  \n",
       "89       2.980708      0       0    1.0       0.005239               0.040929  "
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "respondents_data[(respondents_data['respondent_id'] == 1) & (respondents_data['trip_id'] == 7)].sort_values(by='trip_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This leads to the idea of model goodness-of-fit. We can compare the highest `predicted_choice_prob` value for each `respondent_id` and `trip_id` and verify whether it corresponds to `choice = 1`. The ratio of correctly predicted choices to the total possible choices provides an accuracy measure, as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8543\n"
     ]
    }
   ],
   "source": [
    "df_max_prob = respondents_data.loc[respondents_data.groupby(['respondent_id', 'trip_id'])['predicted_choice_prob'].idxmax()]\n",
    "df_max_prob['correct_prediction'] = df_max_prob['choice'] == 1\n",
    "accuracy = df_max_prob['correct_prediction'].mean()\n",
    "\n",
    "print(f'Accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at an example. For `respondent_id = 0`, the model predicts \"incorrectly\" only once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>respondent_id</th>\n",
       "      <th>trip_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>price</th>\n",
       "      <th>brand_strength</th>\n",
       "      <th>quality_score</th>\n",
       "      <th>group</th>\n",
       "      <th>choice</th>\n",
       "      <th>const</th>\n",
       "      <th>exp_utilities</th>\n",
       "      <th>predicted_choice_prob</th>\n",
       "      <th>correct_prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>1.185260</td>\n",
       "      <td>0.607545</td>\n",
       "      <td>4.878339</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.874885</td>\n",
       "      <td>0.707489</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>2.911052</td>\n",
       "      <td>0.948886</td>\n",
       "      <td>4.579309</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.230619</td>\n",
       "      <td>0.645082</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>2.650641</td>\n",
       "      <td>0.808397</td>\n",
       "      <td>4.687497</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.831159</td>\n",
       "      <td>0.937628</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>2.636425</td>\n",
       "      <td>0.965632</td>\n",
       "      <td>3.391600</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.632534</td>\n",
       "      <td>0.926702</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>2.650641</td>\n",
       "      <td>0.808397</td>\n",
       "      <td>4.687497</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.831159</td>\n",
       "      <td>0.492634</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>1.185260</td>\n",
       "      <td>0.607545</td>\n",
       "      <td>4.878339</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.874885</td>\n",
       "      <td>0.990088</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>1.185260</td>\n",
       "      <td>0.607545</td>\n",
       "      <td>4.878339</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.874885</td>\n",
       "      <td>0.775081</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>2.636425</td>\n",
       "      <td>0.965632</td>\n",
       "      <td>3.391600</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.632534</td>\n",
       "      <td>0.746465</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>2.636425</td>\n",
       "      <td>0.965632</td>\n",
       "      <td>3.391600</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.632534</td>\n",
       "      <td>0.912623</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>1.522753</td>\n",
       "      <td>0.199674</td>\n",
       "      <td>2.246844</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.241795</td>\n",
       "      <td>0.864070</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    respondent_id  trip_id  product_id     price  brand_strength  \\\n",
       "3               0        0          10  1.185260        0.607545   \n",
       "8               0        1          13  2.911052        0.948886   \n",
       "14              0        2          15  2.650641        0.808397   \n",
       "18              0        3          14  2.636425        0.965632   \n",
       "24              0        4          15  2.650641        0.808397   \n",
       "25              0        5          10  1.185260        0.607545   \n",
       "31              0        6          10  1.185260        0.607545   \n",
       "38              0        7          14  2.636425        0.965632   \n",
       "43              0        8          14  2.636425        0.965632   \n",
       "47              0        9           6  1.522753        0.199674   \n",
       "\n",
       "    quality_score  group  choice  const  exp_utilities  predicted_choice_prob  \\\n",
       "3        4.878339      0       1    1.0       7.874885               0.707489   \n",
       "8        4.579309      0       1    1.0       2.230619               0.645082   \n",
       "14       4.687497      0       1    1.0       2.831159               0.937628   \n",
       "18       3.391600      0       1    1.0       0.632534               0.926702   \n",
       "24       4.687497      0       0    1.0       2.831159               0.492634   \n",
       "25       4.878339      0       1    1.0       7.874885               0.990088   \n",
       "31       4.878339      0       1    1.0       7.874885               0.775081   \n",
       "38       3.391600      0       1    1.0       0.632534               0.746465   \n",
       "43       3.391600      0       1    1.0       0.632534               0.912623   \n",
       "47       2.246844      0       1    1.0       0.241795               0.864070   \n",
       "\n",
       "    correct_prediction  \n",
       "3                 True  \n",
       "8                 True  \n",
       "14                True  \n",
       "18                True  \n",
       "24               False  \n",
       "25                True  \n",
       "31                True  \n",
       "38                True  \n",
       "43                True  \n",
       "47                True  "
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_max_prob[df_max_prob['respondent_id'] == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **2. BUSINESS IMPLICATIONS**\n",
    "- Suppose our client is considering discontinuing Product X (choose any item). Based on the model results, where do you expect its sales volume to shift?  \n",
    "- What additional analyses or model enhancements would you recommend to improve sourcing predictions? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to analyze the effect of discontinuing a specific product (in this case, `product_id = 7`), the change in sales volume direction will be examined as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>respondent_id</th>\n",
       "      <th>trip_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>price</th>\n",
       "      <th>brand_strength</th>\n",
       "      <th>quality_score</th>\n",
       "      <th>group</th>\n",
       "      <th>choice</th>\n",
       "      <th>const</th>\n",
       "      <th>exp_utilities</th>\n",
       "      <th>predicted_choice_prob</th>\n",
       "      <th>predicted_choice_prob_new</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>2.911052</td>\n",
       "      <td>0.948886</td>\n",
       "      <td>4.579309</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.230619</td>\n",
       "      <td>0.200402</td>\n",
       "      <td>0.200588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2.403951</td>\n",
       "      <td>0.785176</td>\n",
       "      <td>3.650089</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.934350</td>\n",
       "      <td>0.083943</td>\n",
       "      <td>0.084021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>1.185260</td>\n",
       "      <td>0.607545</td>\n",
       "      <td>4.878339</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.874885</td>\n",
       "      <td>0.707489</td>\n",
       "      <td>0.708148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>8.491984</td>\n",
       "      <td>0.065052</td>\n",
       "      <td>4.757996</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.080545</td>\n",
       "      <td>0.007236</td>\n",
       "      <td>0.007243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.370861</td>\n",
       "      <td>0.611853</td>\n",
       "      <td>1.488153</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.020926</td>\n",
       "      <td>0.006052</td>\n",
       "      <td>0.006070</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   respondent_id  trip_id  product_id     price  brand_strength  \\\n",
       "0              0        0          13  2.911052        0.948886   \n",
       "1              0        0           5  2.403951        0.785176   \n",
       "3              0        0          10  1.185260        0.607545   \n",
       "4              0        0          12  8.491984        0.065052   \n",
       "5              0        1           0  4.370861        0.611853   \n",
       "\n",
       "   quality_score  group  choice  const  exp_utilities  predicted_choice_prob  \\\n",
       "0       4.579309      0       0    1.0       2.230619               0.200402   \n",
       "1       3.650089      0       0    1.0       0.934350               0.083943   \n",
       "3       4.878339      0       1    1.0       7.874885               0.707489   \n",
       "4       4.757996      0       0    1.0       0.080545               0.007236   \n",
       "5       1.488153      0       0    1.0       0.020926               0.006052   \n",
       "\n",
       "   predicted_choice_prob_new  \n",
       "0                   0.200588  \n",
       "1                   0.084021  \n",
       "3                   0.708148  \n",
       "4                   0.007243  \n",
       "5                   0.006070  "
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "respondents_data_new = respondents_data.copy()\n",
    "\n",
    "product_to_remove = 7\n",
    "respondents_data_new = respondents_data_new[respondents_data_new['product_id'] != product_to_remove]\n",
    "respondents_data_new['predicted_choice_prob_new'] = respondents_data_new.groupby(['respondent_id', 'trip_id'])['exp_utilities'].transform(lambda x: x / x.sum())\n",
    "respondents_data_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>predicted_choice_prob</th>\n",
       "      <th>predicted_choice_prob_new</th>\n",
       "      <th>change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>0.109509</td>\n",
       "      <td>0.111208</td>\n",
       "      <td>-0.001700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>0.108146</td>\n",
       "      <td>0.109819</td>\n",
       "      <td>-0.001674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0.142763</td>\n",
       "      <td>0.144358</td>\n",
       "      <td>-0.001594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>0.071948</td>\n",
       "      <td>0.073500</td>\n",
       "      <td>-0.001551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0.240321</td>\n",
       "      <td>0.241833</td>\n",
       "      <td>-0.001512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.220194</td>\n",
       "      <td>0.221572</td>\n",
       "      <td>-0.001378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>16</td>\n",
       "      <td>0.038757</td>\n",
       "      <td>0.039902</td>\n",
       "      <td>-0.001145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0.034759</td>\n",
       "      <td>0.035814</td>\n",
       "      <td>-0.001055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>14</td>\n",
       "      <td>0.368372</td>\n",
       "      <td>0.369334</td>\n",
       "      <td>-0.000961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>11</td>\n",
       "      <td>0.029532</td>\n",
       "      <td>0.030397</td>\n",
       "      <td>-0.000865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5</td>\n",
       "      <td>0.440398</td>\n",
       "      <td>0.441240</td>\n",
       "      <td>-0.000841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>18</td>\n",
       "      <td>0.019001</td>\n",
       "      <td>0.019764</td>\n",
       "      <td>-0.000763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>17</td>\n",
       "      <td>0.019836</td>\n",
       "      <td>0.020559</td>\n",
       "      <td>-0.000723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>0.608464</td>\n",
       "      <td>0.609013</td>\n",
       "      <td>-0.000549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>0.661785</td>\n",
       "      <td>0.662240</td>\n",
       "      <td>-0.000456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>0.008803</td>\n",
       "      <td>0.009138</td>\n",
       "      <td>-0.000336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>9</td>\n",
       "      <td>0.007253</td>\n",
       "      <td>0.007551</td>\n",
       "      <td>-0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>10</td>\n",
       "      <td>0.848867</td>\n",
       "      <td>0.849087</td>\n",
       "      <td>-0.000221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2</td>\n",
       "      <td>0.003361</td>\n",
       "      <td>0.003506</td>\n",
       "      <td>-0.000144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>7</td>\n",
       "      <td>0.017478</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    product_id  predicted_choice_prob  predicted_choice_prob_new    change\n",
       "0           19               0.109509                   0.111208 -0.001700\n",
       "1           12               0.108146                   0.109819 -0.001674\n",
       "2            4               0.142763                   0.144358 -0.001594\n",
       "3            8               0.071948                   0.073500 -0.001551\n",
       "4            3               0.240321                   0.241833 -0.001512\n",
       "5            6               0.220194                   0.221572 -0.001378\n",
       "6           16               0.038757                   0.039902 -0.001145\n",
       "7            0               0.034759                   0.035814 -0.001055\n",
       "8           14               0.368372                   0.369334 -0.000961\n",
       "9           11               0.029532                   0.030397 -0.000865\n",
       "10           5               0.440398                   0.441240 -0.000841\n",
       "11          18               0.019001                   0.019764 -0.000763\n",
       "12          17               0.019836                   0.020559 -0.000723\n",
       "13          13               0.608464                   0.609013 -0.000549\n",
       "14          15               0.661785                   0.662240 -0.000456\n",
       "15           1               0.008803                   0.009138 -0.000336\n",
       "16           9               0.007253                   0.007551 -0.000298\n",
       "17          10               0.848867                   0.849087 -0.000221\n",
       "18           2               0.003361                   0.003506 -0.000144\n",
       "19           7               0.017478                        NaN       NaN"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparison_df = respondents_data.merge(\n",
    "    respondents_data_new[['respondent_id', 'trip_id', 'product_id', 'predicted_choice_prob_new']],\n",
    "    on=['respondent_id', 'trip_id', 'product_id'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "stats_comparison = comparison_df.groupby('product_id')[['predicted_choice_prob', 'predicted_choice_prob_new']].mean().reset_index()\n",
    "stats_comparison['change'] = stats_comparison['predicted_choice_prob'] - stats_comparison['predicted_choice_prob_new']\n",
    "stats_comparison.sort_values(by='change', ascending=True, inplace=True)\n",
    "stats_comparison.reset_index(drop=True, inplace=True)\n",
    "stats_comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"admonition tip alert alert-info\">\n",
    "<p class=\"first admonition-title\" style=\"font-weight: bold;\">Impact of product discontinuation</p>\n",
    "<p class=\"last\">\n",
    "\n",
    "If **product_id = 7** is discontinued, and the **estimated choice probabilities are redistributed for each respondent_id and trip_id combination**, the product_ids that receive the highest redistribution appear in the previous table, with product_id = 19 benefiting the most, followed by product_id = 12, and so on.\n",
    "\n",
    "However, this analysis relies on a **key assumption of the MNL Logit model**: the Independence of Irrelevant Alternatives (IIA) property, which states that the probability ratio between two options remains unchanged when a third option is modified. This assumption may be unrealistic, given the data and the actual (and unknown) substitution patterns between products.\n",
    "\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **3. TECHNICAL RECOMMENDATIONS**\n",
    "- What limitations does a standard MNL model have in answering sourcing questions?  \n",
    "- Suggest a potential improvement.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"admonition tip alert alert-info\">\n",
    "<p class=\"first admonition-title\" style=\"font-weight: bold;\">Final thoughts</p>\n",
    "<p class=\"last\">\n",
    "\n",
    "The MNL model has key limitations in sourcing analysis due to the Independence of Irrelevant Alternatives (IIA) assumption, which prevents it from capturing differentiated substitution patterns. When a product is removed, demand is redistributed proportionally, without distinguishing between close and distant substitutes. Additionally, it assumes preference homogeneity, meaning all consumers respond similarly to changes in price and quality. To improve prediction accuracy, Machine Learning models like Random Forest or XGBoost can be leveraged to capture nonlinear relationships and interaction effects. Furthermore, enriching the model with additional features, such as seasonality, supplier reliability, and macroeconomic indicators (e.g., inflation, exchange rates), can better reflect real market dynamics.\n",
    "\n",
    "</p>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
